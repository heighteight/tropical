%%In this section we illustrate a few directions in which the tropical semantics just introduced could be used to analyze quantitative properties of higher-order programs. 

%Since algebraic and geometric properties in tropical mathematics are usually more tractable from a computational point of view, in several well-known applications (e.g.~for optimization problems related to machine learning \cite{Pachter2004, Zhang2018, Maragos2021}) one starts from a given model, typically expressed by some polynomial function $f$, and studies  what properties of the model can be deduced from the \emph{tropicalization} of $f$, noted $\trop f$, i.e.~the transformation of $f$ into a tropical polynomial. Here we follow a similar pattern: we consider a program $M$, which can be expressed in the form of a polynomial or a power series $f$, and we  investigate what quantitative properties of $M$ can be deduced from the properties of $\trop f$, that will indeed coincide with the interpretation of $M$ in $\LREL_{!}$.

%
%
%%several well-known applications of tropical mathematics is to study how much can be deduced of some function starting from the properties of its tropicalization.
%%In Section \ref{section5} we will follow a similar direction, investigating what quantitative properties of a higher-order programs are revealed by the study of its tropical interpretation.
%

%\input{tropicalization}

\begin{comment}

\subsection{Best case analysis and metric reasoning}

The possibility of using the relational model over the tropical semiring for ``best case'' resource analysis has already been explored in \cite{Manzo2013}. Notably, they considered an interpretation of a language for $\B{PCF}$ with non-deterministic choice in which each $\lambda$-abstraction and each occurrence of the fixpoint operator $Y$ is assigned a ``weight'' 1, and showed that for any program $M$ of type $\B{nat}$, 
the value of the interpretation $\model{M}\in \Lawv^{\BB N}$ on a particular natural number $k$, i.e.~$\model{M}(k)\in \Lawv$, corresponds to the \emph{minimum} number of $\beta$- or $\TT{fix}$-redexes reduced in a reductions sequence from $M$ to $\underline n$. 
In the next paragraph we will illustrate an analogous ``best case'' analysis for probabilistic programs.

What does the metric analysis from the previous sections add to that? Firstly, the possibility of \emph{comparing} different programs with respect to their quantitative properties. For example, in the $\B{PCF}$ semantics recalled above, the distance between two programs $M$ and $N$ of type $\B{nat}$, provides a bound on the difference between the  ``best case'' computation time of $M$ and that of $N$. For instance, by taking, instead of the $\infty$-norm metric on $\Lawv^{\BB N}$,  
the \emph{non symmetric} distance (or quasi-metric, a viewpoint we explicitly take in Section \ref{section6}) $q(\B x, \B y)=\sup_{n}\{\B y_{n}\dotdiv \B x_{n}\}$, a ``distance'' $q(\model{M},\model{N})\leq \epsilon$ would indicate that $\model{M}$ \emph{improves} on $\model{N}$ of at most $\epsilon$ steps at each computation. 

Secondly, the Lipschitz conditions from Section \ref{section4} allow us to reason on program distances in a \emph{compositional} way: suppose, as before, that $M,N:A$ are two programs such that $M$ improves on $N$ by $\epsilon$, and let $\TT C[-]:A \to \B{nat}$ indicate a context; knowing that the interpretation of $\TT C$ is $k$-Lipschitz-continuous on some open set containing both $\model M$ and $\model N$, allows us to immediately deduce that $\TT C[M]$ improves on $\TT C[N]$ by $k \epsilon$. 
Observe that this will typically be the case when the Taylor expansions of $\TT C[M]$ and $\TT C[N]$ actually yields a \emph{finite} sum of at most $k$ terms, i.e.~when 
\begin{align}
\TT C[M] = \sum_{i=0}^{k} \TT D^{(k)}\Big[\lambda x.\TT C[x]\Big]\cdot M^{k}
\end{align}
and similarly for $\TT C[N]$. It is here worth recalling that, for $\STDLC$, a well-known result \cite{difflambda} is that the Taylor expansion of a closed application $MN$ is always \emph{finite}, although its non-zero coefficients may be arbitrarily high. 
Notably, these observations suggest to study tropical versions of \emph{finiteness spaces} \cite{Ehrhard2005}, 
a variant of the relational semantics modeling strongly normalizing programs via \emph{finite} power series.
%We mention this point in Section~\ref{section8}.

\end{comment}

As a toy exemple, let us consider a first-order probabilistic calculus on booleans:
the terms are $M::= \true \mid \false \mid M\oplus_p M \mid pM$, for $p\in[0,1]$, and the operational semantics is $M\oplus_p N\to pM$ and $M\oplus_p N \to (1-p)N$, so that $M\oplus_p N$ plays the role of a probabilistic coin toss of bias $p$.

Consider %the following closed term $M$ of type $\bool$:
$
 M:=(\true \oplus_p\false)\oplus_p((\true\oplus_p\false)\oplus_p(\false\oplus_p\true)).
 $
Let us give addresses $\omega\in\set{ll,lr,rll,rlr,rrl,rrr}$ to the occurrences of $\true,\false$ in $M$, by following the tree structure of $M$, ($l$ is ``left'' and $r$ is ``right'').
The same addresses also represent all the different possible reduction paths from $M$ to a normal form.
%For instance, $rll$ represents the reduction which keeps the right part of the outermost $\oplus_p$ and erases the left part, then continues by choosing the left part twice, reaching at the end the occurrence $\true_{rll}$ in $M$, i.e.\ the second occurrence of $\true$ in $M$ starting from the left.
Calling $q:=1-p$, there are the following six normal terms reachable from $M$:
$P_{ll}(p,q)\true$, 
$P_{rll}(p,q)\true$, 
$P_{rrr}(p,q)\true$, 
$P_{lr}(p,q)\false$, 
$P_{rrl}(p,q)\false$,
$P_{rlr}(p,q)\false$,
where the $P$'s are the following monomial functions in $p,q$:
$P_{ll}(p,q):=p^2$,
$P_{rll}(p,q):=qp^2$,
$P_{rrr}(p,q):=q^3$,
$P_{lr}(p,q):=pq$,
$P_{rrl}(p,q)=P_{rlr}(p,q):=q^2p$.
%They correspond to the respective reduction path from $M$ to the normal term of the same address.
$P_{\omega}(p,1-p)$ is then the probability of the event ``$M\twoheadrightarrow \true_\omega/\false_\omega$'' (depending on $\omega$).
Thinking of $p,q$ as parameters, $P_{\omega}(p,q)$ can thus be read as the \emph{likelihood function} of the event ``$M\twoheadrightarrow \true_\omega/\false_\omega$''.
The polynomial function $Q_{\true}(p,q):=P_{ll}(p,q)+P_{rll}(p,q)+P_{rrr}(p,q)=p^2+p^2q+q^3$ gives instead the probability of the event ``$M\twoheadrightarrow \true$'', and analogously for $Q_{\false}(p,q):=P_{lr}(p,q)+P_{rrl}(p,q)+P_{rlr}(p,q)=pq+2pq^2$.
%Let us consider in this subsection a probabilistic extension of $\lam$-calculus, call it $\STLC_\oplus$, adding as usual terms of shape $pM+qN$ and $M\oplus_p N$, for $p,q\in[l,r]$.These terms are typed via the rule:
%\[
%\dfrac{\Gamma\vdash M:A \qquad \Gamma\vdash N:A}{\Gamma\vdash M\oplus_p N:A}
%\]
%and similar for $\Gamma\vdash pM+qN:A$.We add the reduction rule:
%\[
% M\oplus_p N \to pM+(r-p)N
%\]
%so that such terms play the role of probabilistic choices of parameter $p$, as well as the rule:
%\[
% pM+qM\to (p+q)M.
%\]
%Let us consider $M:=(I\oplus_p\Omega)\oplus_p((I\oplus_p\Omega)\oplus_p(I\oplus_p\Omega))$. Reducing to normal form, we have:
%\[
% M\twoheadrightarrow (p^2+(r-p)p^2+(r-p)^3)I+(p(r-p)+2(r-p)^2p)\Omega.
%\]
%The index $\omega\in\set{ll,rll,rrr,lr,rrl,rlr}$ of each $P_\omega$ indicates the path of the reduction that led from $M$ to the respective occurrence $I_\omega$ of $I$ or $\Omega_\omega$ of $\Omega$ from $M$ to its normal form ($l$ means ``left'' and $r$ means ``right'').For instance, in order to reach $I_{rll}$, i.e.\ the second occurrence of $I$ from the left in $M$, we have to take the right path in the outer $\oplus_p$ of $M$, then two times the left path in the new outer $\oplus_p$'s that we encounter during reduction.$P_{\omega}(p,q)$ gives then the probability (as a function of $p,q$) of obtaining the respective occurrence $I_{\omega}$ or $\Omega_\omega$ in the normal form, if we were to sample at each time we reduce a $\oplus_p$.It can thus also be read as the likelihood function of such event.The polynomials $Q_{r,2}(p,q)$ give instead the whole probability of obtaining respectively $I$ or $\Omega$, in the normal form after such samplings.
This way, the probabilistic evaluation of $M$ is presented as a \emph{hidden Markov model} \cite{Baumr966}, a fundamental statistical model, and notably one to which tropical methods are generally applied \cite{Pachter2ll4}.

Typical questions in this case would be, for a fixed $\omega_0$:
%
%The tropical point of view allows now to express two natural questions about this situation:
\begin{enumerate}
 \item Which is the \emph{maximum likelihood estimator} for the event ``$M\twoheadrightarrow \false_{\omega_0}$''?
 I.e., which is the choice of $p,q$ that maximizes the probability $P_{\omega_0}$ of the event ``$M\twoheadrightarrow \false_{\omega_0}$''  ?
 \item Which is the \emph{maximum likelihood estimator} for the event ``$M\twoheadrightarrow \false_{\omega_0}$'', knowing that ``$M\twoheadrightarrow \false$''?
I.e., which is the choice of $p,q$ that makes $\omega_0$ the most likely path among those leading to $\false$ (i.e.\ that maximizes the conditional probability $\BB P(``M\twoheadrightarrow \false_{\omega_0}'' \mid ``M\twoheadrightarrow \false'')$)?
\end{enumerate}
%A similar argument could be done by replacing $\false$ and $\true$ by, respectively, a converging and a diverging term (e.g.~in a $\B{PCF}$-style language), so r) would be about finding maximum likelihood estimators for the event ``$M$ converges''.

Answering 1) and 2) amounts at solving a maximization problem related to $P_{\omega_0}, Q_{\omega_0}$, which is more easily solved by 
passing to the tropical monomial/polynomial functions $\trop P_{\omega_0},\trop^{\mathrm{val}} Q_{\omega_0}$, for any fixed valuation.
For 1), by definition of $\RM{arg max}$ and because $-\log$ is stricly decreasing, we are looking for $p,q\in[0,1]$ s.t.\ $q=1-p$ and $(p,q)\in
%\begin{equation}
%  \begin{array}{ccccc}
   \RM{arg max}_{(x,y)} P_{\omega_0} (x,y)
   %& 
   = %&
   \RM{arg min}_{(x,y)}\set{-\log P_{\omega_0} (x,y)}
   %&
   =%&
   \RM{arg min}_{(x,y)}\set{(\trop P_{\omega_0}) (-\log x,-\log y)} \label{eq:argmax}$
where this holds for any valuation (because monomials do not carry any coefficient).
Remark that $(\trop P_{\omega})( -\log x, -\log y)$ is precisely the \emph{negative log-probability} of the event ``$M\twoheadrightarrow \false_{\omega}$'', so we see that the tropicalisation allows to compute such quantities.
%  \end{array}
%\end{equation}
For 2), %the $\omega_l$ is s.t.\ $\max\limits_{\omega\in\set{ll,rll,rrr}} \, P_\omega(x,y) = P_{\omega_l}(x,y)$. So
we are looking for $p,q\in[0,1]$ s.t.\ $q=1-p$ and
$\max_{\omega\in\set{lr,rrl,rlr}} \, P_\omega(p,q) = P_{\omega_0}(p,q)$, i.e.\ $\min_{\omega\in\set{lr,rrl,rlr}} \, -\log P_\omega(p,q) = -\log P_{\omega_0}(p,q)$.
Remembering that $\trop^{\mathrm{val}} Q_{\false}(p,q)=\min\set{p+q, \mathrm{val}(2)+p+2q}$, we see that our minimization problem is equivalent to asking $(\trop^{\mathrm{val}_1} Q_{\false})( -\log p, -\log q) = (\trop^{\mathrm{val}_1} P_{\omega_0})( -\log p, -\log q)\label{eq:max}$,
and this time this holds, in general, only for the trivial valuation.
Remark that, in both cases, passing through $\trop^0 $ %P_\omega, \trop Q_\omega$ 
makes the problem easier, as this amounts to study tropical polynomials (for instance computing tropical roots can be done in linear time \cite{Noferini2lr5}), and this essentially corresponds to study negative log-probabilities. %the tropicalisation operator $\trop{}$ as well as the \emph{negative $\log$-probabilities} appear.

%For our running example $M$, we have $\trop Q_{\true}(x,y)=\min\set{2x,y+2x,3y}$ and $\trop Q_{\false}(x,y)=\min\set{x+y,2y+x}$. Studying $\trop Q_{\true}$ %, whose plot is in Fig.~\ref{fig:plot2}, we see that $\trop Q_{\true}(x,y)=3y$ iff $y\leq \frac{2}{3}x$, and it coincides with $2x$ otherwise. Remembering that $3y=P_{rrr}(x,y)$, we can now solve the optimisation problem~\ref{eq:max} for $\omega_l=rrr$: via the substitution $x:=-\log p$, $y:=-\log (r-p)$, Equation~\ref{eq:max} is equivalent to $-\log (r-p)\leq -\frac{2}{3}\log_c p$, i.e.\ $r-p\geq p^{\frac{2}{3}}$. This means that, for $p\in[0,1]$ s.t.\ $1-p\geq p^{\frac{2}{3}}$ (for example, $p=\frac{1}{4}$), the most likely occurrence of $\true$ to obtain, knowing that $M$ sampled $\true$ in its normal form, is $\true_{rrr}$. Remembering that $2x=P_{ll}(x,y)$, for the other values of $p$ (for example, $p=\frac{1}{2}$), the most likely $\true$ to be sampled is the occurrence $\true_{ll}$. We have thus answered question 2) above for $\true$.

Our toy first-order language can be interpreted in $\LREL$.
We do not give details now since in the rest of the paper we will interpret interesting \emph{high-order} calculi, including a probabilistic one containing our toy language.
We notice the following important:

\begin{remark}\label{rmk:tropof01Rel}
$\model{M}^{\LREL}_0(-\log p,-\log (1-p))$ gives the minimum negative log-probability of all the reductions from $M$ to normal form, i.e.\ it coincides with the  negative log-probability of any of the (equiprobable) \emph{most} likely reductions from $M$ to normal form.
Equivalently, given $\omega_0$ a fixed reduction path from $M$ to normal form $P_{\omega_0}$, for all solution $p\in[0,1]$ to the equation $%\trop P_\omega(-\log p, -\log(1-p)) 
-\log  P_{\omega_0} = \model{M}^{\LREL}_0(-\log p,-\log (1-p))$, the path $\omega_0$ is one of the \emph{most} likely one among all paths from $M$ to normal form.
Similarly, $\model{M}^{\LREL}_0(\log p,\log (1-p))$ gives the minimum log-probability of all the reductions from $M$ to normal form, i.e.\ it coincides with the log-probability of any of the (equiprobable) \emph{less} likely reductions from $M$ to normal form.
Equivalently, given $\omega_0$ a fixed reduction path from $M$ to normal form $P_{\omega_0}$, for all solution $p\in[0,1]$ to the equation $%\trop P_\omega(\log p, \log(1-p)) 
\log  P_{\omega_0} = \model{M}^{\LREL}_0(\log p,\log (1-p))$, the path $\omega_0$ is one of the \emph{less} likely one among all paths from $M$ to normal form.
% (in $p$ and $q$, not after the substitution $q:=r-p$) 
% are extracted from it, \ref{eq:argmax}, \ref{eq:max} of $\STLC_\oplus$-programs. 
\end{remark}

\begin{remark}
Our toy first-order language can be also interpreted both in the already mentioned $\overline{R_{\geq 0}}\mathrm{Rel}$.
But it is important to mention already at this point that the probabilities we just discussed above, are already captured by the $[0,\infty]\mathrm{Rel}$ model: the $\model{M}^{\overline{R_{\geq 0}}\mathrm{Rel}}\in[0,\infty]^{\set{0,1}}$ of our running example $M$ is $\model M_0=Q_{\false}(p,1-p)$, $\model M_1=Q_{\true}(p,1-p)$.
Therefore, the optimisation problems concerning the negative log-probabilities and likelihoods are already expressible by taking $\trop^{\mathrm{val}_1}\model{M}^{\overline{R_{\geq 0}}\mathrm{Rel}}$. 
Now, the model $\LREL$ is precisely trivial-valuation tropicalisation of $\overline{R_{\geq 0}}\mathrm{Rel}$, i.e.\ $\model{M}^{\LREL}=\trop^{\mathrm{val}_1}\model{M}^{\overline{R_{\geq 0}}\mathrm{Rel}}$.
As we remarked in \autoref{rmk:val_trop}, this corresponds to quotienting the polynomial interpreting $\model{M}^{\overline{R_{\geq 0}}\mathrm{Rel}}$ w.r.t.\ idempotent sum.
A precise study of the ``tropicalisation of $\overline{R_{\geq 0}}\mathrm{Rel}$'' is left for future investigations, as it is related with power series arising from more sophisticated calculi with paramethers (in the style of \cite{} {\color{red}Ehrhard!}).
However, it is important to keep in mind that those properties are expressed by $\LREL$ directly with no need to pass through a tropicalsation.
\end{remark}

%Now, in $\LREL$, seen as a model of such probabilistic $\lam$-calculus, the interpretation of a term already computes the tropicalisation of the polynomials expressing the probabilities, because the underlying semiring of the model is tropical.
%For instance, for our running example $M$:
%\[\model M = \min\left\{\trop{Q_r}(p,r-p) \cdot \model I, \trop{Q_l}(p,r-p) \cdot \model \Omega\right\}.\]

